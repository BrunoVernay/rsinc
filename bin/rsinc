#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ****************************************************************************
# *                                 Imports                                  *
# ****************************************************************************

import argparse
import os
import subprocess
import time
import ujson as json
import logging
from datetime import datetime

import halo
from clint.textui import colored

DRIVE_DIR = '~/.rsinc/'  # Where config and data files live
DRIVE_DIR = os.path.expanduser(DRIVE_DIR)

THESAME = 0
UPDATED = 1
DELETED = 2
CREATED = 3

# ****************************************************************************
# *                                  Classes                                 *
# ****************************************************************************


class File():
    def __init__(self, name, uid, time, state):
        self.name = name
        self.uid = uid
        self.time = time
        self.state = state
        self.moved = False
        self.is_clone = False
        self.synced = False


class Flat():
    def __init__(self, path):
        self.path = path
        self.files = []
        self.uids = {}
        self.names = {}
        self.lower = set({})

    def update(self, name, uid, time, state=THESAME):
        self.files.append(File(name, uid, time, state))
        self.names.update({name: self.files[-1]})
        self.lower.add(name.lower())

        if uid in self.uids:
            self.names[name].is_clone = True
            self.uids[uid].is_clone = True
        else:
            self.uids.update({uid: self.files[-1]})

    def clean():
        for file in self.files:
            file.synced = False


# ****************************************************************************
# *                                 Functions                                *
# ****************************************************************************


def qt(string):
    return '"' + string + '"'


def read(file):
    '''Reads json do dict and returns dict'''
    with open(file, 'r') as fp:
        d = json.load(fp)

    return d


def write(file, d):
    '''Writes dict to json'''
    if not dry_run:
        with open(file, 'w') as fp:
            json.dump(d, fp, sort_keys=True, indent=2)


def prepend(name, prefix):
    '''
    Adds 'prefix' to the begging of the file name, 'name' and returns the new
    name
    '''
    new_name = name.split('/')
    new_name[-1] = prefix + new_name[-1]
    new_name = '/'.join(new_name)
    return new_name


def lsl(path):
    '''
    Runs rclone lsjson on path and returns a dict containing each file with the
    uid and last modified time
    '''
    command = ['rclone', 'lsjson', '-R', '--files-only', '--hash', path]

    result = subprocess.Popen(command, stdout=subprocess.PIPE)

    list_of_dicts = json.load(result.stdout)

    out = Flat(path)
    for d in list_of_dicts:
        time = d['ModTime'][:19]
        time = datetime.strptime(time, "%Y-%m-%dT%H:%M:%S").timestamp()

        hashsize = str(d['Size'])
        hashsize += d['Hashes'][HASH_NAME]

        out.update(d['Path'], hashsize, time)

    return out


def calc_states(old, new):
    '''
    Calculates if files on one side have been updated, moved, deleted,
    created or stayed the same. Arguments are both Flats.
    '''
    for name, file in new.names.items():
        if name in old.names:
            if old.names[name].uid != file.uid:
                file.state = UPDATED
            else:
                file.state = THESAME
        elif file.uid in old.uids and not file.is_clone:
            file.moved = True
            file.state = THESAME
        else:
            file.state = CREATED

    for name, file in old.names.items():
        if name not in new.names and (file.uid not in new.uids or file.is_clone):
            new.update(name, file.uid, file.time, DELETED)


def r_sync(lcl, rmt):
    '''Recovery sync function'''
    t_rmt = [rmt, Flat('new_rmt')]  # For all names in rmt
    t_lcl = [lcl, Flat('new_lcl')]  # For all names in lcl

    for name, file in lcl.names.items():
        if name in rmt.names:
            if file.uid != rmt.names[name].uid:
                if file.time > rmt.names[name].time:
                    push(lcl.path + name, rmt.path + name)
                else:
                    pull(lcl.path + name, rmt.path + name)

        elif file.uid in rmt.uids and not file.is_clone and not rmt.uids[uid].is_clone:
            if file.time > rmt.uids[file.uid].time:
                nn = move(rmt.uids[file.uid].name, name, t_rmt, t_rmt)
                nn = balance_names(name, nn, t_lcl, t_rmt)
            else:
                name = rename(lcl.path, name, [pulled, lcl])
                move(lcl.path + name, lcl.path + rmt.uids[file.uid].name)
                pulled.update(name, file.uid, file.time)
        else:
            name = rename(lcl.path, name, [rmt, pushed])
            push(lcl.path + name, rmt.path + name)
            pushed.update(name, file.uid, file.time)

    for name, file in rmt.names.items():
        if name not in lcl.names and \
                (file.uid not in lcl.uids or file.is_clone or
                 (file.uid in lcl.uids and lcl.uids[file.uid].is_clone)):

            name = rename(rmt.path, name, [lcl, pulled])
            pull(lcl.path + name, rmt.path + name)
            pulled.update(name, file.uid, file.time)


def sync(old, lcl, rmt)
    t_rmt = [rmt, Flat('new_rmt')]  # For all names in rmt
    t_lcl = [lcl, Flat('new_lcl')]  # For all names in lcl

    _sync(old, lcl, rmt, t_lcl, t_rmt)
    _sync(old, rmt, lcl, t_rmt, t_lcl)

    lcl.clean()
    rmt.clean()


SAME = 0
MOVED = 1
CLONE = 2
NOT = 3


def calc_mv_state(file, rmt)
    if file.is_clone:
        i = CLONE
    elif file.moved:
        i = MOVED
    else:
        i = SAME

    if file.name not in rmt.names:
        j = NOT
    else:
        if rmt.names[name].is_clone:
            j = CLONE
        elif rmt.names[name].moved:
            j = MOVED
        else:
            j = SAME

    return (i, j)


def _sync(old, lcl, rmt, t_lcl, t_rmt):
    '''Normal sync function'''

    for name, file in lcl.names.items():
        if file.synced:
            continue
        s = calc_mv_state(file, rmt)

        if s == (SAME, SAME)
        if s == (NCM, NCNM) or (0, 1)


#     nn = move(name, rmt.uids[file.uid].name, t_lcl, t_lcl)
#     nn = balance_names(nn, rmt.uids[file.uid].name, t_lcl, t_rmt)
# elif file.uid in rmt.uids and rmt.uids[file.uid].is_clone:
#     # Both moved, rmt is clone
#     nn = rename(lcl.path, name, [rmt, pushed])
#     push(lcl.path + nn, rmt.path + nn)
#     pushed.update(nn, file.uid, file.time)
# else:
#     # Only lcl moved
#     nn = move(old.uids[file.uid].name, name, t_rmt, t_rmt)
#     nn = balance_names(name, nn, t_lcl, t_rmt)

#     rmoved.update(old.uids[file.uid].name, file.uid, file.time)

#     LOGIC[THESAME][rmt.names[old.uids[file.uid].name].state](
#         lcl.path + nn, rmt.path + nn)

def null(*args):
    return


def balance_names(name_lcl, name_rmt, flats_lcl=[], flats_rmt=[]):
    '''Used to match names when a move and rename generates a case conflict'''
    nn_lcl = name_lcl
    nn_rmt = name_rmt

    while nn_lcl != nn_rmt:
        nn_lcl = nn_rmt
        resolve_case(nn_lcl, flats_lcl)
        resolve_case(nn_rmt, flats_rmt)

    if nn_lcl != name_lcl:
        move(name_lcl, nn_lcl, flats_lcl, flats_lcl)
    if nn_rmt != name_rmt:
        move(name_rmt, nn_rmt, flats_rmt, flats_rmt)

    return nn_lcl


def resolve_case(name, flats=[]):
    '''
    Detects if 'name_s' has any case conflicts in any of the Flat()'s in 
    'flats_d'. If it does name is modified until no case conflicts occur and the 
    new name returned
    '''
    if not CASE_INSENSATIVE:
        return name_d

    new_name = name

    for flat in flats:
        while new_name.lower() in flat.lower:
            new_name = prepend(new_name, '_')

    return new_name


def move(name_s, name_d, flats_s=[], flats_d=[]):
    '''Move source to dest'''
    global counter
    counter += 1

    for flat in flats_d:
        if name_d in flats_d.names:
            print(red('ERROR:'), name_d, 'in', flats_d[0].path)

    new_name_d = resolve_case(name_d, flats_d)

    source = flats_s[0].path + name_s
    dest = flats_d[0].path + new_name_d

    if not dry_run:
        print('%d/%d' % (counter, total_jobs) +
              ylw(' Move: ') + source + cyn(' to: ') + dest)
        logging.info('MOVE: %s TO %s', source, dest)
        subprocess.run(['rclone', 'moveto', source, dest])
    else:
        print(ylw('Move: ') + source + cyn(' to: ') + dest)

    if name_d == new_name_d:
        flats_d[1].update(new_name_d, 'null', 0)

    return new_name_d


def push(source, dest):
    '''Copy source (at local) to dest (at remote)'''
    global counter, LOG
    counter += 1

    if not dry_run:
        print('%d/%d' % (counter, total_jobs) + cyn(' Push: ') + source)
        logging.info('PUSH: %s', source)
        subprocess.run(['rclone', 'copyto', source, dest])
    else:
        print(cyn("Push: ") + source)


def pull(dest, source):
    '''Copy source (at remote) to dest (at local)'''
    global counter, LOG
    counter += 1

    if not dry_run:
        print('%d/%d' % (counter, total_jobs) + mgt(' Pull: ') + source)
        logging.info('PULL: %s', source)
        subprocess.run(['rclone', 'copyto', source, dest])
    else:
        print(mgt("Pull: ") + source)


def conflict(source, dest):
    '''Rename and copy conflicts both ways'''

    print(red('Conflict: ') + source)

    if not dry_run:
        logging.warning('CONFLICT: %s', source)

    move(source, prepend(source, 'lcl_'))
    move(dest, prepend(dest, 'rmt_'))

    push(prepend(source, 'lcl_'), prepend(dest, 'lcl_'))
    pull(prepend(source, 'rmt_'), prepend(dest, 'rmt_'))


def delL(local, remote):
    '''Delete local (at local)'''
    global counter
    counter += 1

    if not dry_run:
        print('%d/%d' % (counter, total_jobs) + ylw(' Delete: ') + local)
        logging.info('DELETE: %s', local)
        subprocess.run(['rclone', 'delete', local])
    else:
        print(ylw("Delete: ") + local)


def delR(local, remote):
    '''Delete remote (at remote)'''
    delL(remote, local)


# ****************************************************************************
# *              Functions for working with packed dictionary's              *
# ****************************************************************************


def empty():
    '''Returns dict representing empty directory'''
    return {'fold': {}, 'file': {}}


def insert(nest, chain):
    '''Inserts element at the end of the chain into packed dict, nest'''
    if len(chain) == 2:
        nest['file'].update({chain[0]: chain[1]})
        return

    if chain[0] not in nest['fold']:
        nest['fold'].update({chain[0]: empty()})

    insert(nest['fold'][chain[0]], chain[1:])


def pack(flat):
    '''Converts flat, into packed dict'''
    nest = empty()
    for file in flat.files:
        chain = file.name.split(
            '/') + [{'uid': file.uid, 'datetime': file.time}]
        insert(nest, chain)

    return nest


def unpack(nest, flat, path=''):
    '''Converts packed dict, nest, into flat'''
    for k, v in nest['file'].items():
        flat.update(path + k, v['uid'], v['datetime'])

    for k, v in nest['fold'].items():
        unpack(v, flat, path + k + '/')


def _get_branch(nest, chain):
    '''Returns packed dict at end of chain in packed dict, nest'''
    if len(chain) == 0:
        return nest
    else:
        return _get_branch(nest['fold'][chain[0]], chain[1:])


def get_branch(nest, path):
    '''Helper function for _get_branch, converts path to chain'''
    return _get_branch(nest, path.split('/'))


def _merge(nest, chain, new):
    '''Merge packed dict, new, into packed dict, nest, at end of chain'''
    if len(chain) == 1:
        nest['fold'].update({chain[0]: new})
        return

    if chain[0] not in nest['fold']:
        nest['fold'].update({chain[0]: empty()})

    _merge(nest['fold'][chain[0]], chain[1:], new)


def merge(nest, path, new):
    '''Helper function for _merge, converts path to chain'''
    _merge(nest, path.split('/'), new)


def _have(nest, chain):
    '''Returns: true if chain is contained in packed dict, nest, else: false'''
    if chain[0] in nest['fold']:
        if len(chain) == 1:
            return True
        else:
            return _have(nest['fold'][chain[0]], chain[1:])

    return False


def have(master, path):
    '''Helper function for _have, converts path to chain'''
    return _have(master, path.split('/'))


def _get_min(nest, chain, min_chain):
    '''Returns the subset of chain contained in packed dict, nest'''
    if len(chain) == 1:
        return min_chain
    elif chain[0] not in nest['fold']:
        return min_chain
    else:
        min_chain.append(chain[1])
        return _get_min(nest['fold'][chain[0]], chain[1:], min_chain)


def get_min(master, path):
    '''Helper function for _get_min, converts path to chain'''
    chain = path.split('/')
    min_chain = _get_min(master, chain, [chain[0]])
    return '/'.join(min_chain)


# ****************************************************************************
# *                           Definitions / Set-up                           *
# ****************************************************************************


print('''
Copyright 2019 C. J. Williams (CHURCHILL COLLEGE)
This is free software with ABSOLUTELY NO WARRANTY''')

config = read(DRIVE_DIR + 'config.json')

BASE_R = config['BASE_R']
BASE_L = config['BASE_L']
CASE_INSENSATIVE = config['CASE_INSENSATIVE']
HASH_NAME = config['HASH_NAME']
DEFAULT_DIRS = config['DEFAULT_DIRS']


strtobool = {'yes': True, 'ye': True, 'y': True, 'n': False, 'no': False,
             '1': True, "0": False, 't': True, 'true': True, 'f': False,
             'false': False, 'Y': True, 'N': False, 'Yes': True, "No": False,
             '': True}

ylw = colored.yellow   # delete/move
cyn = colored.cyan     # push
mgt = colored.magenta  # pull
red = colored.red      # error/conflict
grn = colored.green    # info

spin = halo.Halo(spinner='dots', placement='right', color='yellow')

LOGIC = [[null, pull, delL, conflict],
         [push, conflict, push, conflict],
         [delR, pull, null, pull],
         [conflict, conflict, push, conflict], ]

# Decide which folder(s) to sync
CWD = os.getcwd()
cwd = CWD.split('/')
for elem in BASE_L.split('/')[:-1]:
    if cwd[0] == elem:
        cwd.pop(0)
    else:
        cwd = DEFAULT_DIRS
        break
else:
    if len(cwd) == 0:
        cwd = DEFAULT_DIRS
    else:
        cwd = ['/'.join(cwd)]

# Set up logging
log_file = DRIVE_DIR + 'logs/' + datetime.now().strftime('%Y-%m-%d')
logging.basicConfig(filename=log_file, level=logging.DEBUG, datefmt='%H:%M:%S',
                    format='%(asctime)s %(levelname)s: %(message)s')


# ****************************************************************************
# *                             Parsing Arguments                            *
# ****************************************************************************


parser = argparse.ArgumentParser()

parser.add_argument("folders", help="Folders to sync", nargs='*')
parser.add_argument("-d", "--dry", action="store_true", help="Do a dry run")
parser.add_argument("-c", "--clean", action="store_true",
                    help="Clean directories")
parser.add_argument("-D", "--default", help="Sync defaults",
                    action="store_true")
parser.add_argument("-r", "--recovery", action="store_true",
                    help="Enter recovery mode")
parser.add_argument("-a", "--auto", help="Don't ask permissions",
                    action="store_true")
parser.add_argument("-p", "--purge", help="Reset history for all folders",
                    action="store_true")
parser.add_argument("-s", "--save", help="Force save state to master",
                    action="store_true")

args = parser.parse_args()

if args.default:
    folders = DEFAULT_DIRS
elif args.folders == []:
    folders = cwd
else:
    folders = args.folders

dry_run = args.dry
auto = args.auto
recover = args.recovery


# ****************************************************************************
# *                               Main Program                               *
# ****************************************************************************

if args.purge:
    print(ylw('WARN'), 'Purging history of all folders')
    write(DRIVE_DIR + 'master.json', empty())

# get the master structure
if not os.path.exists(DRIVE_DIR + 'master.json'):
    print(ylw('WARN'), '"master.json" missing, this must be your first run')
    write(DRIVE_DIR + 'master.json', empty())

master = read(DRIVE_DIR + 'master.json')

if os.path.exists(DRIVE_DIR + 'rsinc.tmp'):
    print(red('ERROR') + ', detected a crash, found rsinc.tmp')

    corrupt = read(DRIVE_DIR + 'rsinc.tmp')['folder']
    if corrupt in folders:
        folders.remove(corrupt)

    folders.insert(0, corrupt)
    recover = True
    logging.warning('Detected crash, recovering %s', corrupt)

for folder in folders:
    print('')
    save = False

    path_lcl = BASE_L + folder + '/'
    path_rmt = BASE_R + folder + '/'

    min_path = get_min(master, folder)

    # Determine if first run
    if have(master, folder):
        print(grn('Have:'), qt(folder) + ', entering sync & merge mode')
    else:
        print(ylw('Don\'t have:'), qt(folder) + ', entering first_sync mode')
        recover = True
        save = True

    # Scan directories
    spin.start(("Crawling: ") + qt(folder))

    lcl = lsl(path_lcl)
    rmt = lsl(path_rmt)
    old = Flat('old')

    spin.stop_and_persist(symbol='✔')

    # First run & recover mode
    if recover:
        print('Running', ylw('recover/first_sync'), 'mode')
    else:
        print('Reading last state.')
        branch = get_branch(master, folder)
        unpack(branch, old)

        calc_states(old, lcl)
        calc_states(old, rmt)

    # Main logic
    dry_run = True
    counter = 0

    print(grn('Dry pass:'))
    sync(old, lcl, rmt)

    dry_run = args.dry
    total_jobs = counter

    if dry_run:
        print('Found:', counter, 'job(s)')
    else:
        if counter == 0:
            print('Found no jobs')
        elif auto or strtobool[input('Execute? ')]:
            print(grn("Live pass:"))
            counter = 0
            save = True

            write(DRIVE_DIR + 'rsinc.tmp', {'folder': folder})
            sync(old, lcl, rmt)

        if args.clean:
            spin.start(grn('Pruning: ') + qt(min_path))

            subprocess.run(["rclone", 'rmdirs', path_rmt])
            subprocess.run(["rclone", 'rmdirs', path_lcl])

            spin.stop_and_persist(symbol='✔')

    # Merge into master and clean up
    if save:
        spin.start(grn('Saving: ') + qt(min_path))

        merge(master, min_path, pack(lsl(BASE_L + min_path)))
        write(DRIVE_DIR + 'master.json', master)

        if os.path.exists(DRIVE_DIR + 'rsinc.tmp'):
            subprocess.run(["rm", DRIVE_DIR + 'rsinc.tmp'])

        spin.stop_and_persist(symbol='✔')

    recover = args.recovery

print('')
print(grn("All synced!"))
